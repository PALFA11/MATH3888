{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b169cb-df24-4d90-a9c1-5d5f81bf6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import markov_clustering as mc\n",
    "from networkx.algorithms.community import fast_label_propagation_communities\n",
    "import random\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8ec6d5-9bc0-4832-99a8-ef638bdbe640",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '4932.protein.links.v12.0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mread_weighted_edgelist(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4932.protein.links.v12.0.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,comments \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m,nodetype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# remove some edges, guess we're doing 700 now \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u, v \u001b[38;5;129;01min\u001b[39;00m g\u001b[38;5;241m.\u001b[39medges:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/networkx/utils/backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/networkx/readwrite/edgelist.py:481\u001b[0m, in \u001b[0;36mread_weighted_edgelist\u001b[0;34m(path, comments, delimiter, create_using, nodetype, encoding)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;129m@nx\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(graphs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_weighted_edgelist\u001b[39m(\n\u001b[1;32m    430\u001b[0m     path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    435\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    436\u001b[0m ):\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read a graph as list of edges with numeric weights.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m    write_weighted_edgelist\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_edgelist(\n\u001b[1;32m    482\u001b[0m         path,\n\u001b[1;32m    483\u001b[0m         comments\u001b[38;5;241m=\u001b[39mcomments,\n\u001b[1;32m    484\u001b[0m         delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m    485\u001b[0m         create_using\u001b[38;5;241m=\u001b[39mcreate_using,\n\u001b[1;32m    486\u001b[0m         nodetype\u001b[38;5;241m=\u001b[39mnodetype,\n\u001b[1;32m    487\u001b[0m         data\u001b[38;5;241m=\u001b[39m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m),),\n\u001b[1;32m    488\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    489\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/networkx/utils/decorators.py:770\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argmap\u001b[38;5;241m.\u001b[39m_lazy_compile(__wrapper)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 5:3\u001b[0m, in \u001b[0;36margmap_read_edgelist_1\u001b[0;34m(path, comments, delimiter, create_using, nodetype, data, edgetype, encoding, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/networkx/utils/decorators.py:193\u001b[0m, in \u001b[0;36mopen_file.<locals>._open_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;66;03m# could be None, or a file handle, in which case the algorithm will deal with it\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m fobj \u001b[38;5;241m=\u001b[39m _dispatch_dict[ext](path, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fobj, \u001b[38;5;28;01mlambda\u001b[39;00m: fobj\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '4932.protein.links.v12.0.txt'"
     ]
    }
   ],
   "source": [
    "g = nx.read_weighted_edgelist('4932.protein.links.v12.0.txt',comments = \"#\",nodetype=str)\n",
    "\n",
    "# remove some edges, guess we're doing 700 now \n",
    "for u, v in g.edges:\n",
    "    if g.get_edge_data(u, v)['weight'] < 700:\n",
    "      g.remove_edge(u, v)\n",
    "\n",
    "#remove weights\n",
    "for node, edges in nx.to_dict_of_dicts(g).items():\n",
    "    for edge, attrs in edges.items():\n",
    "        attrs.pop('weight', None)\n",
    "\n",
    "matrix = nx.to_numpy_array(g)\n",
    "node_list = list(g.nodes)\n",
    "related_proteins = ['4932.YMR190C','4932.YNL088W','4932.YLR234W','4932.YPL024W','4932.YMR167W' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb418e11-ffdb-476f-9b78-6cebd53889f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcl(mtx,inflation_parameter):\n",
    "    result = mc.run_mcl(mtx,inflation = inflation_parameter)\n",
    "    clusters = mc.get_clusters(result)\n",
    "\n",
    "    #relabelling node names \n",
    "    for i in range(0,len(clusters)):\n",
    "        clu_list = list(clusters[i])\n",
    "        \n",
    "        for j in range(0,len(clu_list)):\n",
    "            name = node_list[clu_list[j]]\n",
    "            clu_list[j] = name\n",
    "        clusters[i] = tuple(clu_list)\n",
    "\n",
    "    return inflation_parameter, result, clusters\n",
    "\n",
    "def similarity_of_clusterings(clusters1,name1, clusters2,name2, num):\n",
    "    clusters1 = sorted(clusters1,key = len, reverse = True)\n",
    "    clusters2 = sorted(clusters2,key = len, reverse = True)\n",
    "\n",
    "    sim_dict = {}\n",
    "    for i in range(0,len(clusters1)) :\n",
    "        similarity = []\n",
    "        for j in range(0,len(clusters2)):\n",
    "            counter = 0\n",
    "            for k in clusters1[i]:\n",
    "                if k in clusters2[j]:\n",
    "                    counter +=1\n",
    "                    \n",
    "            # bool = 0: shit sim meas, bool = 1: jaccards\n",
    "            if num == 0:\n",
    "                score = 2*counter/(len(clusters1[i])+len(clusters2[j]))\n",
    "            elif num == 1:\n",
    "                score = counter/(len(clusters1[i])+len(clusters2[j])-counter)\n",
    "                \n",
    "            if score > 0:\n",
    "                similarity.append((str(name2)+str(j),len(clusters2[j]),score))\n",
    "        similarity = sorted(similarity, key = lambda x:x[-1], reverse= True)\n",
    "        sim_dict[(str(name1)+str(i),len(clusters1[i]))] = similarity\n",
    "    return sim_dict\n",
    "\n",
    "def large_comm(cluster,threshold):\n",
    "    large = []\n",
    "    for i in cluster:\n",
    "        if len(i)>=threshold:\n",
    "            large.append(i)\n",
    "\n",
    "    return large\n",
    "\n",
    "def similarity_of_algo(dict):\n",
    "    score_list=[]\n",
    "    for i in dict: \n",
    "        score_list.append(i[1]*dict[i][0][-1])\n",
    "    score = sum(score_list)/6538\n",
    "    \n",
    "    return score, score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654501f-3a8f-4e2d-bea6-639c32113121",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('markov_clustering_14.pkl', 'rb') as file:\n",
    "    markov_clustering_14 = pickle.load(file)\n",
    "clusters = markov_clustering_14[2]\n",
    "\n",
    "with open('Fast_PP_1.pkl', 'rb') as file:\n",
    "    label_prop_1 = pickle.load(file)\n",
    "label_prop_1 = sorted(label_prop_1, key=len,reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb20fb-b754-4b2a-bf40-e0991ddcaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_of_clusterings(large_comm(label_prop_1,30),'lp',large_comm(clusters,30),'mc',0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
